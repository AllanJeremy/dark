#!/usr/bin/env python3.6

import subprocess
import sys
import threading
import time

run_tests = False

# Make io unbuffered
def flush(fn):
  def newfn(x):
    fn(x)
    sys.stdout.flush()
  return newfn
sys.stdout.write = flush(sys.stdout.write)
sys.stdout.writelines = flush(sys.stdout.writelines)


def run(bash):
  proc = subprocess.run(bash, shell=True)
  return proc.returncode == 0


def compile(files):
  global run_tests
  if run_tests:
    test = "--test "
  else:
    test = ""
  run("scripts/support/compile " + test + " ".join(files))


def initial_compile():
  files = [ "client/elm-package.json"
          , "client/Main.elm"
          , "server/main/dark.ml"
          , "server/static/base.less"
          , "client/Tests/elm-package.json"
          , "server/test/test.ml" ]
  compile(files)

  print("--------------------------")
  print("-- Finished initial compile")
  print("--------------------------")


def start_postgres():
  print("--------------------------")
  print("-- Starting postgres")
  print("--------------------------")
  run('sudo su postgres -c "/etc/init.d/postgresql start"')

# It is extremely challenging to get a non-blocking read on stdin.
# Essentially, we want to read everything from stdin and then compile.
# And if there isn't anything on stdin, sleep for a bit. The best way
# to do that is to read stdin in a separate thread, and every 300ms to
# check what has accumulated. Every other option I tried, including
# termios, epoll, either didn't work, or had a weird edge case. One
# nasty edge case is when you're saving all the time, as my editor is
# configured to do, it processes it one at a time and builds up a huge
# list of touched files, which it does one at a time, regardless of
# what's behind it in the queue.

inputBuffer = []
bufferLock = threading.Lock()
def process_watchers():
  global inputBuffer

  class InputThread(threading.Thread):
    def run(self):
      global inputBuffer
      while True:
        line = sys.stdin.readline()
        bufferLock.acquire()
        inputBuffer.insert(0,line)
        bufferLock.release()

  input_thread=InputThread()
  input_thread.daemon=True
  input_thread.start()

  while True:
    if len(inputBuffer) == 0:
      time.sleep(0.1)
    else:
      bufferLock.acquire()
      input = inputBuffer.copy()
      inputBuffer.clear()
      bufferLock.release()

      files = set()
      for line in input:
        for f in line.split("\n"):
          if f != "":
            try:
              f, _ = f.strip().split(" ")
              files.add(f)
            except:
              print("exception splitting: " + f)
      compile(files)

def background_task(fn):
  threading.Thread(target=fn).start()

def main():
  watch = False
  compile = False

  for f in sys.argv[1:]:
    if f == "--compile":
      compile = True
    elif f == "--watch":
      watch = True
    elif f == "--test":
      global run_tests
      run_tests = True

  if compile:
    background_task(initial_compile)
    background_task(start_postgres)

  if watch:
    process_watchers()

  for t in threading.enumerate():
    if t != threading.main_thread():
      t.join()


main()

